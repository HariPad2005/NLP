{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming\n",
    "\n",
    "Stemming is a method in text processing that eliminates prefixes and suffixes from words, transforming them into their fundamental or root form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['play','plays','playing','player','played','swiftly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "pstemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "play\t\tplay\n",
      "plays\t\tplay\n",
      "playing\t\tplay\n",
      "player\t\tplayer\n",
      "played\t\tplay\n",
      "swiftly\t\tswiftli\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(f\"{word}\\t\\t{pstemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "words2 = ['machen','suchen','brauchen','kaufen','arbeiten']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "sstemmer = SnowballStemmer(language = 'german')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machen\t\tmach\n",
      "suchen\t\tsuch\n",
      "brauchen\t\tbrauch\n",
      "kaufen\t\tkauf\n",
      "arbeiten\t\tarbeit\n"
     ]
    }
   ],
   "source": [
    "for word in words2:\n",
    "  print(f\"{word}\\t\\t{sstemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp1 = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t\t PRON \t\t 4690420944186131903 \t\t I \t\t nsubj\n",
      "'m \t\t AUX \t\t 10382539506755952630 \t\t be \t\t aux\n",
      "searching \t\t VERB \t\t 295895373269394349 \t\t search \t\t ROOT\n",
      "for \t\t ADP \t\t 16037325823156266367 \t\t for \t\t prep\n",
      "my \t\t PRON \t\t 227504873216781231 \t\t my \t\t poss\n",
      "shoes \t\t NOUN \t\t 12623266062479156681 \t\t shoe \t\t pobj\n",
      ". \t\t PUNCT \t\t 12646065887601541794 \t\t . \t\t punct\n",
      "Have \t\t AUX \t\t 14692702688101715474 \t\t have \t\t aux\n",
      "you \t\t PRON \t\t 7624161793554793053 \t\t you \t\t nsubj\n",
      "seen \t\t VERB \t\t 11925638236994514241 \t\t see \t\t ROOT\n",
      "them \t\t PRON \t\t 16875582379069451158 \t\t they \t\t dobj\n",
      "? \t\t PUNCT \t\t 8205403955989537350 \t\t ? \t\t punct\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp1(\"I'm searching for my shoes. Have you seen them?\")\n",
    "for token in doc1:\n",
    "  print(token.text, \"\\t\\t\", token.pos_, '\\t\\t',token.lemma, '\\t\\t', token.lemma_, '\\t\\t',token.dep_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "German Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('de_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Ich suche meine Schuhe. Hast du sie gesehen?\")\n",
    "#I'm searching for my shoes. Have you seen them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ich \t\t PRON \t\t 5864527961345014045 \t\t ich\n",
      "suche \t\t VERB \t\t 18313823129771624139 \t\t suchen\n",
      "meine \t\t DET \t\t 7570793064135359215 \t\t mein\n",
      "Schuhe \t\t NOUN \t\t 3240750755112541786 \t\t Schuh\n",
      ". \t\t PUNCT \t\t 10501404726543969396 \t\t --\n",
      "Hast \t\t VERB \t\t 13575293068407610524 \t\t Hast\n",
      "du \t\t PRON \t\t 17166863280368009634 \t\t du\n",
      "sie \t\t PRON \t\t 13323500956662843128 \t\t sie\n",
      "gesehen \t\t VERB \t\t 5513153705242160378 \t\t sehen\n",
      "? \t\t PUNCT \t\t 10501404726543969396 \t\t --\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "  print(token.text, \"\\t\\t\", token.pos_, '\\t\\t',token.lemma, '\\t\\t', token.lemma_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lemmas(doc3):\n",
    "    for token in doc3:\n",
    "        print(f'{token.text:{14}} {token.pos_:{8}} {token.lemma:<{22}} {token.lemma_:{14}} {token.dep_:{14}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(\"Der schnelle braune Fuchs springt über den faulen Hund.\")\n",
    "#The quick brown fox jumps over the lazy dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der            DET      9250722957692387333    der            nk            \n",
      "schnelle       ADJ      12679834086485348841   schnell        nk            \n",
      "braune         ADJ      16884188031653587216   braun          nk            \n",
      "Fuchs          PROPN    7428125815056104837    Fuchs          sb            \n",
      "springt        VERB     10557456600538100282   springen       ROOT          \n",
      "über           ADP      1502415808165053963    über           mo            \n",
      "den            DET      9250722957692387333    der            nk            \n",
      "faulen         ADJ      12760680308645965638   faul           nk            \n",
      "Hund           NOUN     4759838677326765497    Hund           nk            \n",
      ".              PUNCT    10501404726543969396   --             punct         \n"
     ]
    }
   ],
   "source": [
    "show_lemmas(doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization using WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faster----fast\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "text = \"faster\"\n",
    "result = lemmatizer.lemmatize(text,pos='a')\n",
    "print(f\"{text}----{result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'daher', 'gleich', 'ihren', 'indem', 'endlich', 'gibt', 'drin', 'sondern', 'diesen', 'ihn', 'jeden', 'das', 'beispiel', 'vom', 'ehrlich', 'müssen', 'zehn', 'für', 'großen', 'ihr', 'offen', 'oder', 'nicht', 'ausser', 'durften', 'siebentes', 'drittes', 'ins', 'dieses', 'erstes', 'lange', 'vierten', 'rechtes', 'grossen', 'ging', 'mit', 'her', 'drei', 'auch', 'wo', 'darf', 'darüber', 'seines', 'eigenen', 'gegen', 'sowie', 'neunter', 'machte', 'sehr', 'können', 'keiner', 'lang', 'des', 'na', 'meines', 'eigen', 'jenes', 'solcher', 'en', 'lieber', 'darauf', 'ganze', 'willst', 'wem', 'dass', 'diese', 'sagte', 'eigene', 'manchen', 'solchen', 'dahin', 'konnten', 'weiteres', 'großer', 'daselbst', 'achte', 'wird', 'davon', 'seinem', 'dagegen', 'eben', 'niemanden', 'an', 'ihm', 'gern', 'zehnte', 'seit', 'demgegenüber', 'dementsprechend', 'auf', 'bald', 'sollte', 'muß', 'gross', 'hätten', 'statt', 'will', 'anderem', 'währenddem', 'wann', 'da', 'nur', 'magst', 'zusammen', 'welcher', 'allerdings', 'dich', 'jemanden', 'allem', 'welche', 'natürlich', 'mochten', 'kam', 'viertes', 'zweite', 'vierte', 'ag', 'nie', 'einer', 'als', 'hier', 'neunten', 'vor', 'noch', 'dies', 'darum', 'waren', 'siebte', 'wohl', 'diesem', 'mancher', 'geschweige', 'weit', 'beiden', 'mir', 'deren', 'gehabt', 'mag', 'zur', 'viel', 'grosse', 'hinter', 'guter', 'seien', 'satt', 'am', 'darfst', 'in', 'durch', 'alle', 'euch', 'sieben', 'gutes', 'ach', 'hast', 'seitdem', 'zuerst', 'je', 'einiger', 'einmaleins', 'zehntes', 'jeder', 'geht', 'wäre', 'mehr', 'demzufolge', 'müsst', 'durfte', 'gar', 'daneben', 'sagt', 'siebente', 'jemandem', 'deiner', 'sechster', 'allein', 'durchaus', 'nach', 'meinem', 'jedermann', 'aber', 'unsere', 'gemocht', 'ebenso', 'siebter', 'kaum', 'du', 'einen', 'los', 'jenem', 'danach', 'macht', 'richtig', 'er', 'unter', 'geworden', 'neben', 'machen', 'seiner', 'ich', 'achtes', 'besser', 'jedem', 'rund', 'solchem', 'selbst', 'vielem', 'denn', 'wieder', 'diejenige', 'die', 'oft', 'jahre', 'mögt', 'kurz', 'seine', 'uhr', 'während', 'weitere', 'allgemeinen', 'bisher', 'kleines', 'deshalb', 'schon', 'siebten', 'gekannt', 'wenigstens', 'jahren', 'dieselben', 'gerade', 'keinen', 'sei', 'der', 'gedurft', 'siebenter', 'dir', 'währenddessen', 'einem', 'deswegen', 'zwar', 'diejenigen', 'wahr', 'zeit', 'ja', 'desselben', 'mich', 'wollte', 'heisst', 'mögen', 'dürfen', 'seid', 'überhaupt', 'dessen', 'welches', 'tun', 'ein', 'dermaßen', 'bereits', 'heißt', 'sollen', 'wurde', 'eigenes', 'kann', 'acht', 'zehnter', 'dasein', 'anderen', 'besonders', 'es', 'außer', 'ihrer', 'oben', 'bei', 'kleinen', 'darunter', 'man', 'gemusst', 'dank', 'doch', 'solches', 'hatten', 'sich', 'haben', 'vergangene', 'um', 'kleiner', 'neun', 'kleine', 'hatte', 'gewesen', 'andern', 'keinem', 'andere', 'wollen', 'ist', 'wirklich', 'dritten', 'dadurch', 'viele', 'nein', 'sechsten', 'einander', 'habe', 'demgemäss', 'außerdem', 'mochte', 'fünftes', 'mussten', 'werdet', 'a', 'jenen', 'rechten', 'eine', 'sie', 'aller', 'jahr', 'könnt', 'etwas', 'tagen', 'bekannt', 'siebtes', 'hat', 'ersten', 'entweder', 'demgemäß', 'erste', 'zunächst', 'gekonnt', 'zu', 'derselbe', 'gehen', 'darin', 'jedoch', 'wegen', 'wollt', 'später', 'tage', 'dabei', 'zweites', 'wurden', 'werde', 'derjenigen', 'ab', 'mittel', 'gut', 'möchte', 'würden', 'alles', 'kannst', 'vergangenen', 'ausserdem', 'große', 'ganzen', 'jemand', 'hin', 'manche', 'infolgedessen', 'damals', 'bist', 'nichts', 'dahinter', 'vier', 'wer', 'derselben', 'also', 'demselben', 'jene', 'neunte', 'grosser', 'dieser', 'so', 'manchem', 'daran', 'gute', 'dort', 'wie', 'habt', 'á', 'hoch', 'besten', 'leider', 'vielleicht', 'wirst', 'kommen', 'damit', 'dem', 'beide', 'nahm', 'und', 'meinen', 'weiter', 'neuntes', 'zehnten', 'soll', 'zweiter', 'würde', 'möglich', 'den', 'muss', 'dazwischen', 'sonst', 'rechte', 'achten', 'zweiten', 'sind', 'teil', 'gegenüber', 'was', 'zwischen', 'fünfter', 'groß', 'einige', 'weniger', 'kein', 'einiges', 'vielen', 'deine', 'rechter', 'könnte', 'fünf', 'gesagt', 'derjenige', 'unser', 'über', 'wir', 'trotzdem', 'erster', 'daraus', 'bin', 'sah', 'dann', 'genug', 'worden', 'daß', 'dafür', 'hätte', 'ihres', 'ganz', 'niemand', 'musst', 'deinem', 'zwanzig', 'siebenten', 'mein', 'warum', 'dritter', 'sechs', 'dazu', 'ohne', 'solche', 'weniges', 'dermassen', 'unserer', 'im', 'wollten', 'fünfte', 'konnte', 'seinen', 'tag', 'aus', 'neue', 'uns', 'welchem', 'elf', 'einigen', 'immer', 'neuen', 'dasselbe', 'dein', 'ganzer', 'recht', 'bis', 'meiner', 'manches', 'dürft', 'werden', 'dieselbe', 'davor', 'wenig', 'übrigens', 'allen', 'ganzes', 'tel', 'zurück', 'gab', 'leicht', 'ihre', 'irgend', 'von', 'jedermanns', 'keine', 'weil', 'jede', 'wenige', 'ihnen', 'grosses', 'sollten', 'niemandem', 'zwei', 'nachdem', 'wart', 'eigener', 'achter', 'musste', 'gewollt', 'gemacht', 'ob', 'denen', 'welchen', 'einmal', 'sechste', 'eines', 'zum', 'schlecht', 'großes', 'kommt', 'jener', 'wen', 'tat', 'ihrem', 'wessen', 'sechstes', 'zugleich', 'anders', 'beim', 'erst', 'ende', 'morgen', 'fünften', 'sein', 'heute', 'war', 'etwa', 'solang', 'nun', 'vierter', 'wenn', 'denselben', 'dritte', 'jetzt', 'meine', 'weiteren', 'früher'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp.Defaults.stop_words)#german Stop words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
